#!/usr/bin/env python3

# sudo pip3 install beautifulsoup4 requests lxml

from __future__ import print_function

from bs4 import BeautifulSoup
import cookiejar, cookies
import requests
import sys, os
import argparse

#location_choices = list(configured_envs)
#location_choices.append('all')
#location_choices.append('none')

parser = argparse.ArgumentParser(description='Search Places.')
parser.add_argument('-l', '--location', type=str, default=all, help='Specify the location ID to search')
parser.add_argument('-ma', '--make', type=str, default=all, help='Specify the make')
parser.add_argument('-mo', '--model', type=str, default=all, help='Specify the model')


def fetch_html(make, model,i):
    url = 'http://www.carolinapicknpull.com/inventory/?make=%s&model=%s&inventory-search=Search' % (make, model)

      # To handle cookies with requests, ignore the Requests documentation
      # that says to use a RequestCookieJar: that's apparently only for
      # setting cookies, not fetching them. Instead, use a Session:
    session = requests.Session()
    session.cookies.set('cpnp-location',i)
    r = session.get(url)

    return r.text

def do_search(soup, model):
    # case-insensitive search:
    model = model.lower()

    table = soup.find("table", class_="inventoryData")
    if not table:
        print("Nothing found")
        return None
    matches = []
    for tr in table.findAll("tr"):
        if tr.find('th'):
            # Save the values to use as keys
            keys = [ th.text for th in tr.findAll('th') ]
            continue

        vals = [ td.text for td in tr.findAll('td') ]

        if vals[1].lower() == model:
            matches.append(vals)

    return matches

if __name__ == '__main__':

    args = parser.parse_args()
    location = args.location
    model = args.model
    make = args.make


    # Pass the desired make and model as arguments
    #if len(sys.argv) < 3:
    #    print("Usage: %s make model" % os.path.basename(sys.argv[0]))
    #    sys.exit(1)
    #make = sys.argv[1]
    #model = sys.argv[2]
    #locations = ['3','9','10']
    for i in location:
      if i == '3':
          location = 'Cape Fear PickNPull'
      elif i == '9':
          location = 'Grand Strand PickNPull'
      elif i == '10':
          location = 'Sand Hills PickNPull'

      html = fetch_html(make, model, i)
      soup = BeautifulSoup(html, 'lxml')
      matches = do_search(soup, model)
      if not matches603403

          print("No matches")
          sys.exit(0)

      fmt = '%15s %10s %4s %6s %11s'
      print(location)
      print(fmt % ('Make', 'Model', 'Year', 'Row', 'Date-In'))
      for match in matches:
          print(fmt % tuple(match))
